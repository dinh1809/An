"""
ðŸ§  ADVANCED COGNITIVE TRAIT ANALYZER
=====================================
Analyzes deep cognitive metrics from advanced assessment games:
- N-Back (Working Memory)
- Stroop (Inhibition Control)  
- Wisconsin Card Sort (Cognitive Flexibility)

Outputs:
- Trait Classification (Intellectual Processor, Zen Master, Adaptive Solver)
- Composite Cognitive Profile
- Recommendations for Growth Plan

Ethical Constraints:
- Vietnamese language output
- No medical/diagnostic terms
- Supportive, strength-based framing
"""

from dataclasses import dataclass, field
from typing import Dict, List, Optional, Any, Tuple
from enum import Enum
import json

# ============================================================================
# DATA MODELS
# ============================================================================

class Trait(Enum):
    """Special cognitive traits based on assessment performance."""
    INTELLECTUAL_PROCESSOR = "intellectual_processor"  # High working memory
    ZEN_MASTER = "zen_master"  # High inhibition control
    ADAPTIVE_SOLVER = "adaptive_solver"  # High flexibility
    PATTERN_SEEKER = "pattern_seeker"  # High visual-logic combo
    HYPER_FOCUS = "hyper_focus"  # Low impulse + high accuracy
    CREATIVE_THINKER = "creative_thinker"  # High flexibility + below-average structure


@dataclass
class NBackMetrics:
    """Metrics from N-Back (TimeWarpCargo) game."""
    max_n_level: int = 1
    accuracy_percent: float = 0.0
    avg_reaction_time_ms: int = 0
    working_memory_score: int = 0
    d_prime: float = 0.0


@dataclass
class StroopMetrics:
    """Metrics from Stroop (CommandOverride) game."""
    impulse_error_rate: float = 0.0
    avg_reaction_time_ms: int = 0
    inhibition_score: int = 0
    stroop_effect: int = 0
    zen_master_achieved: bool = False


@dataclass
class WisconsinMetrics:
    """Metrics from Wisconsin Card Sort (FluxMatrix) game."""
    perseverative_errors: int = 0
    total_errors: int = 0
    categories_completed: int = 0
    flexibility_index: float = 0.0
    adaptive_solver_achieved: bool = False
    conceptual_level_responses: int = 0


@dataclass
class AdvancedCognitiveProfile:
    """Complete cognitive profile from all advanced assessments."""
    # Raw metrics
    nback: Optional[NBackMetrics] = None
    stroop: Optional[StroopMetrics] = None
    wisconsin: Optional[WisconsinMetrics] = None
    
    # Derived traits
    traits: List[Trait] = field(default_factory=list)
    
    # Composite scores (0-100)
    working_memory_score: int = 50
    inhibition_score: int = 50
    flexibility_score: int = 50
    processing_speed_score: int = 50
    
    # Overall
    cognitive_efficiency_index: float = 0.5


# ============================================================================
# TRAIT DETECTION RULES
# ============================================================================

def detect_traits(profile: AdvancedCognitiveProfile) -> List[Trait]:
    """
    Rule-based trait detection from cognitive metrics.
    
    Rules:
    - INTELLECTUAL_PROCESSOR: N-Back level >= 2
    - ZEN_MASTER: Impulse errors < 10%
    - ADAPTIVE_SOLVER: Flexibility index > 0.8
    - PATTERN_SEEKER: High working memory + high flexibility
    - HYPER_FOCUS: Low impulse + high accuracy across tests
    """
    traits = []
    
    # Rule 1: Intellectual Processor
    if profile.nback and profile.nback.max_n_level >= 2:
        traits.append(Trait.INTELLECTUAL_PROCESSOR)
    
    # Rule 2: Zen Master
    if profile.stroop and profile.stroop.zen_master_achieved:
        traits.append(Trait.ZEN_MASTER)
    
    # Rule 3: Adaptive Solver
    if profile.wisconsin and profile.wisconsin.adaptive_solver_achieved:
        traits.append(Trait.ADAPTIVE_SOLVER)
    
    # Rule 4: Pattern Seeker (compound trait)
    if (profile.nback and profile.wisconsin and 
        profile.nback.max_n_level >= 2 and 
        profile.wisconsin.flexibility_index >= 0.6):
        traits.append(Trait.PATTERN_SEEKER)
    
    # Rule 5: Hyper Focus
    if (profile.stroop and profile.nback and
        profile.stroop.impulse_error_rate < 5 and
        profile.nback.accuracy_percent >= 90):
        traits.append(Trait.HYPER_FOCUS)
    
    # Rule 6: Creative Thinker (flexible but less structured)
    if (profile.wisconsin and profile.nback and
        profile.wisconsin.flexibility_index >= 0.7 and
        profile.nback.max_n_level == 1):
        traits.append(Trait.CREATIVE_THINKER)
    
    return traits


# ============================================================================
# SCORE NORMALIZATION
# ============================================================================

def normalize_to_100(value: float, min_val: float, max_val: float) -> int:
    """Normalize a value to 0-100 scale."""
    if max_val == min_val:
        return 50
    normalized = (value - min_val) / (max_val - min_val) * 100
    return max(0, min(100, int(normalized)))


def calculate_composite_scores(profile: AdvancedCognitiveProfile) -> AdvancedCognitiveProfile:
    """Calculate normalized composite scores from raw metrics."""
    
    # Working Memory Score (from N-Back)
    if profile.nback:
        # Weight: N-level (40%), accuracy (30%), working memory score (30%)
        n_level_score = normalize_to_100(profile.nback.max_n_level, 1, 3)
        accuracy_score = profile.nback.accuracy_percent
        wm_raw = profile.nback.working_memory_score
        
        profile.working_memory_score = int(
            n_level_score * 0.4 + 
            accuracy_score * 0.3 + 
            wm_raw * 0.3
        )
    
    # Inhibition Score (from Stroop)
    if profile.stroop:
        profile.inhibition_score = profile.stroop.inhibition_score
    
    # Flexibility Score (from Wisconsin)
    if profile.wisconsin:
        # Weight: flexibility index (50%), categories (30%), low perseverative errors (20%)
        flex_score = profile.wisconsin.flexibility_index * 100
        category_score = normalize_to_100(profile.wisconsin.categories_completed, 0, 6)
        error_penalty = min(30, profile.wisconsin.perseverative_errors * 3)
        
        profile.flexibility_score = max(0, int(
            flex_score * 0.5 + 
            category_score * 0.3 + 
            (100 - error_penalty) * 0.2
        ))
    
    # Processing Speed (combined reaction times)
    rt_scores = []
    if profile.nback and profile.nback.avg_reaction_time_ms > 0:
        # Lower RT = higher score, baseline 400-1500ms
        rt_scores.append(normalize_to_100(
            1500 - profile.nback.avg_reaction_time_ms, 
            0, 1100
        ))
    if profile.stroop and profile.stroop.avg_reaction_time_ms > 0:
        rt_scores.append(normalize_to_100(
            1000 - profile.stroop.avg_reaction_time_ms,
            0, 600
        ))
    
    if rt_scores:
        profile.processing_speed_score = int(sum(rt_scores) / len(rt_scores))
    
    # Overall Cognitive Efficiency Index
    scores = [
        profile.working_memory_score,
        profile.inhibition_score,
        profile.flexibility_score,
        profile.processing_speed_score
    ]
    valid_scores = [s for s in scores if s > 0]
    if valid_scores:
        profile.cognitive_efficiency_index = sum(valid_scores) / len(valid_scores) / 100
    
    return profile


# ============================================================================
# TRAIT DESCRIPTIONS (Vietnamese)
# ============================================================================

TRAIT_DESCRIPTIONS = {
    Trait.INTELLECTUAL_PROCESSOR: {
        "name_vi": "Bá»™ xá»­ lÃ½ TrÃ­ tuá»‡",
        "description_vi": "CÃ³ kháº£ nÄƒng lÆ°u trá»¯ vÃ  xá»­ lÃ½ nhiá»u thÃ´ng tin cÃ¹ng lÃºc trong trÃ­ nhá»› lÃ m viá»‡c.",
        "strengths_vi": ["Giáº£i quyáº¿t váº¥n Ä‘á» phá»©c táº¡p", "Há»c cÃ¡c quy táº¯c má»›i nhanh", "MÃ£ hÃ³a/láº­p trÃ¬nh"],
        "activities_vi": ["Rubik's Cube", "Cá» vua", "Láº­p trÃ¬nh Scratch/Python"],
        "icon": "brain"
    },
    Trait.ZEN_MASTER: {
        "name_vi": "Thiá»n sÆ° BÃ¬nh tÄ©nh",
        "description_vi": "CÃ³ kháº£ nÄƒng kiá»ƒm soÃ¡t xung Ä‘á»™ng tá»‘t, khÃ´ng hÃ nh Ä‘á»™ng vá»™i vÃ ng dÃ¹ bá»‹ Ã¡p lá»±c.",
        "strengths_vi": ["Táº­p trung cao", "Äiá»m tÄ©nh dÆ°á»›i Ã¡p lá»±c", "Ra quyáº¿t Ä‘á»‹nh cáº©n tháº­n"],
        "activities_vi": ["Thiá»n/Yoga", "Xáº¿p hÃ¬nh tá»‰ má»‰", "Nghá»‡ thuáº­t chi tiáº¿t"],
        "icon": "lotus"
    },
    Trait.ADAPTIVE_SOLVER: {
        "name_vi": "NgÆ°á»i Giáº£i quyáº¿t Linh hoáº¡t",
        "description_vi": "CÃ³ kháº£ nÄƒng chuyá»ƒn Ä‘á»•i cÃ¡ch tiáº¿p cáº­n khi Ä‘iá»u kiá»‡n thay Ä‘á»•i.",
        "strengths_vi": ["ThÃ­ch nghi nhanh", "Linh hoáº¡t tÆ° duy", "SÃ¡ng táº¡o trong giáº£i phÃ¡p"],
        "activities_vi": ["TrÃ² chÆ¡i chiáº¿n thuáº­t", "Brainstorming", "Thá»­ nghiá»‡m khoa há»c"],
        "icon": "shuffle"
    },
    Trait.PATTERN_SEEKER: {
        "name_vi": "NgÆ°á»i TÃ¬m Quy luáº­t",
        "description_vi": "CÃ³ kháº£ nÄƒng nháº­n ra cÃ¡c máº«u áº©n vÃ  quy luáº­t trong dá»¯ liá»‡u phá»©c táº¡p.",
        "strengths_vi": ["PhÃ¡t hiá»‡n quy luáº­t", "PhÃ¢n tÃ­ch logic", "TÆ° duy há»‡ thá»‘ng"],
        "activities_vi": ["Sudoku", "PhÃ¢n loáº¡i bá»™ sÆ°u táº­p", "Data analysis"],
        "icon": "grid"
    },
    Trait.HYPER_FOCUS: {
        "name_vi": "SiÃªu Táº­p trung",
        "description_vi": "CÃ³ kháº£ nÄƒng duy trÃ¬ sá»± táº­p trung cao Ä‘á»™ trong thá»i gian dÃ i vá»›i Ä‘á»™ chÃ­nh xÃ¡c cao.",
        "strengths_vi": ["CÃ´ng viá»‡c Ä‘Ã²i há»i Ä‘á»™ chÃ­nh xÃ¡c", "Kiá»ƒm tra/QC", "NghiÃªn cá»©u sÃ¢u"],
        "activities_vi": ["Puzzle 1000+ máº£nh", "MÃ´ hÃ¬nh chi tiáº¿t", "Quan sÃ¡t thiÃªn vÄƒn"],
        "icon": "target"
    },
    Trait.CREATIVE_THINKER: {
        "name_vi": "NgÆ°á»i SÃ¡ng táº¡o",
        "description_vi": "CÃ³ tÆ° duy má»Ÿ, linh hoáº¡t, thÃ­ch khÃ¡m phÃ¡ nhiá»u gÃ³c nhÃ¬n khÃ¡c nhau.",
        "strengths_vi": ["TÆ° duy ngoÃ i khuÃ´n khá»•", "Ã tÆ°á»Ÿng má»›i", "Káº¿t ná»‘i Ã½ tÆ°á»Ÿng xa"],
        "activities_vi": ["Nghá»‡ thuáº­t tá»± do", "Viáº¿t sÃ¡ng táº¡o", "Thiáº¿t káº¿/Design thinking"],
        "icon": "lightbulb"
    }
}


# ============================================================================
# ANALYSIS FUNCTIONS
# ============================================================================

def analyze_advanced_metrics(data: Dict[str, Any]) -> AdvancedCognitiveProfile:
    """
    Main analysis function.
    
    Input: Raw metrics dictionary from frontend
    Output: Complete cognitive profile with traits and scores
    """
    profile = AdvancedCognitiveProfile()
    
    # Parse N-Back metrics
    if "nback" in data and data["nback"]:
        nback_data = data["nback"]
        profile.nback = NBackMetrics(
            max_n_level=nback_data.get("maxNLevel", 1),
            accuracy_percent=nback_data.get("accuracyPercent", 0),
            avg_reaction_time_ms=nback_data.get("avgReactionTimeMs", 0),
            working_memory_score=nback_data.get("workingMemoryScore", 0),
            d_prime=nback_data.get("dPrime", 0)
        )
    
    # Parse Stroop metrics
    if "stroop" in data and data["stroop"]:
        stroop_data = data["stroop"]
        profile.stroop = StroopMetrics(
            impulse_error_rate=stroop_data.get("impulseErrorRate", 0),
            avg_reaction_time_ms=stroop_data.get("avgReactionTimeMs", 0),
            inhibition_score=stroop_data.get("inhibitionScore", 0),
            stroop_effect=stroop_data.get("stroopEffect", 0),
            zen_master_achieved=stroop_data.get("zenMasterAchieved", False)
        )
    
    # Parse Wisconsin metrics
    if "wisconsin" in data and data["wisconsin"]:
        wisconsin_data = data["wisconsin"]
        profile.wisconsin = WisconsinMetrics(
            perseverative_errors=wisconsin_data.get("perseverativeErrors", 0),
            total_errors=wisconsin_data.get("totalErrors", 0),
            categories_completed=wisconsin_data.get("categoriesCompleted", 0),
            flexibility_index=wisconsin_data.get("flexibilityIndex", 0),
            adaptive_solver_achieved=wisconsin_data.get("adaptiveSolverAchieved", False),
            conceptual_level_responses=wisconsin_data.get("conceptualLevelResponses", 0)
        )
    
    # Calculate composite scores
    profile = calculate_composite_scores(profile)
    
    # Detect traits
    profile.traits = detect_traits(profile)
    
    return profile


def generate_trait_report(profile: AdvancedCognitiveProfile) -> Dict[str, Any]:
    """Generate a human-readable trait report in Vietnamese."""
    
    report = {
        "summary_vi": "",
        "traits": [],
        "composite_scores": {
            "working_memory": profile.working_memory_score,
            "inhibition": profile.inhibition_score,
            "flexibility": profile.flexibility_score,
            "processing_speed": profile.processing_speed_score,
            "overall": round(profile.cognitive_efficiency_index * 100)
        },
        "strengths_vi": [],
        "recommended_activities_vi": [],
        "growth_focus_vi": ""
    }
    
    # Add trait information
    for trait in profile.traits:
        trait_info = TRAIT_DESCRIPTIONS.get(trait, {})
        report["traits"].append({
            "id": trait.value,
            "name_vi": trait_info.get("name_vi", ""),
            "description_vi": trait_info.get("description_vi", ""),
            "icon": trait_info.get("icon", "star")
        })
        
        # Aggregate strengths and activities
        report["strengths_vi"].extend(trait_info.get("strengths_vi", []))
        report["recommended_activities_vi"].extend(trait_info.get("activities_vi", []))
    
    # Remove duplicates
    report["strengths_vi"] = list(set(report["strengths_vi"]))[:5]
    report["recommended_activities_vi"] = list(set(report["recommended_activities_vi"]))[:5]
    
    # Generate summary
    if profile.traits:
        trait_names = [TRAIT_DESCRIPTIONS[t]["name_vi"] for t in profile.traits if t in TRAIT_DESCRIPTIONS]
        report["summary_vi"] = f"Báº¡n cÃ³ xu hÆ°á»›ng: {', '.join(trait_names)}."
    else:
        report["summary_vi"] = "Há»“ sÆ¡ nháº­n thá»©c cá»§a báº¡n Ä‘ang Ä‘Æ°á»£c xÃ¢y dá»±ng."
    
    # Determine growth focus
    lowest_score = min(
        report["composite_scores"]["working_memory"],
        report["composite_scores"]["inhibition"],
        report["composite_scores"]["flexibility"]
    )
    
    if lowest_score == report["composite_scores"]["working_memory"]:
        report["growth_focus_vi"] = "Táº­p trung phÃ¡t triá»ƒn trÃ­ nhá»› lÃ m viá»‡c qua cÃ¡c trÃ² chÆ¡i ghi nhá»›."
    elif lowest_score == report["composite_scores"]["inhibition"]:
        report["growth_focus_vi"] = "Táº­p trung phÃ¡t triá»ƒn kháº£ nÄƒng kiá»ƒm soÃ¡t xung Ä‘á»™ng qua thiá»n vÃ  yoga."
    else:
        report["growth_focus_vi"] = "Táº­p trung phÃ¡t triá»ƒn tÆ° duy linh hoáº¡t qua cÃ¡c hoáº¡t Ä‘á»™ng thá»­ nghiá»‡m."
    
    return report


def profile_to_json(profile: AdvancedCognitiveProfile) -> str:
    """Serialize profile to JSON for storage/API response."""
    data = {
        "nback": None,
        "stroop": None,
        "wisconsin": None,
        "traits": [t.value for t in profile.traits],
        "composite_scores": {
            "working_memory": profile.working_memory_score,
            "inhibition": profile.inhibition_score,
            "flexibility": profile.flexibility_score,
            "processing_speed": profile.processing_speed_score
        },
        "cognitive_efficiency_index": profile.cognitive_efficiency_index
    }
    
    if profile.nback:
        data["nback"] = {
            "maxNLevel": profile.nback.max_n_level,
            "accuracyPercent": profile.nback.accuracy_percent,
            "avgReactionTimeMs": profile.nback.avg_reaction_time_ms,
            "workingMemoryScore": profile.nback.working_memory_score,
            "dPrime": profile.nback.d_prime
        }
    
    if profile.stroop:
        data["stroop"] = {
            "impulseErrorRate": profile.stroop.impulse_error_rate,
            "avgReactionTimeMs": profile.stroop.avg_reaction_time_ms,
            "inhibitionScore": profile.stroop.inhibition_score,
            "stroopEffect": profile.stroop.stroop_effect,
            "zenMasterAchieved": profile.stroop.zen_master_achieved
        }
    
    if profile.wisconsin:
        data["wisconsin"] = {
            "perseverativeErrors": profile.wisconsin.perseverative_errors,
            "totalErrors": profile.wisconsin.total_errors,
            "categoriesCompleted": profile.wisconsin.categories_completed,
            "flexibilityIndex": profile.wisconsin.flexibility_index,
            "adaptiveSolverAchieved": profile.wisconsin.adaptive_solver_achieved,
            "conceptualLevelResponses": profile.wisconsin.conceptual_level_responses
        }
    
    return json.dumps(data, ensure_ascii=False, indent=2)


# ============================================================================
# EXAMPLE USAGE
# ============================================================================

if __name__ == "__main__":
    # Example input from frontend
    example_data = {
        "nback": {
            "maxNLevel": 2,
            "accuracyPercent": 85.5,
            "avgReactionTimeMs": 650,
            "workingMemoryScore": 78,
            "dPrime": 2.1
        },
        "stroop": {
            "impulseErrorRate": 8.5,
            "avgReactionTimeMs": 420,
            "inhibitionScore": 82,
            "stroopEffect": 45,
            "zenMasterAchieved": True
        },
        "wisconsin": {
            "perseverativeErrors": 5,
            "totalErrors": 12,
            "categoriesCompleted": 4,
            "flexibilityIndex": 0.85,
            "adaptiveSolverAchieved": True,
            "conceptualLevelResponses": 78
        }
    }
    
    # Analyze
    profile = analyze_advanced_metrics(example_data)
    
    # Generate report
    report = generate_trait_report(profile)
    
    print("=" * 60)
    print("ðŸ§  ADVANCED COGNITIVE PROFILE")
    print("=" * 60)
    print(f"\nðŸ“Š Summary: {report['summary_vi']}")
    print(f"\nðŸŽ¯ Traits: {[t['name_vi'] for t in report['traits']]}")
    print(f"\nðŸ’ª Strengths: {report['strengths_vi']}")
    print(f"\nðŸŽ® Recommended: {report['recommended_activities_vi']}")
    print(f"\nðŸ“ˆ Focus: {report['growth_focus_vi']}")
    print(f"\nðŸ“Š Scores:")
    for key, value in report['composite_scores'].items():
        print(f"   - {key}: {value}")
    
    print("\n" + "=" * 60)
    print("JSON Output:")
    print(profile_to_json(profile))
